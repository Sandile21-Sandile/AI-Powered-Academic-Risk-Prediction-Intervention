import os
import glob
import argparse
import json
import pandas as pd
import numpy as np
from sklearn.model_selection import (train_test_split, StratifiedKFold,
                                     cross_val_score, cross_val_predict,
                                     RandomizedSearchCV)
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, confusion_matrix, roc_auc_score,
                             classification_report, mean_squared_error)
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
import joblib


def load_data(csv_path='student_records11.csv'):
    # Try to load CSV
    df_csv = None
    if os.path.exists(csv_path):
        print(f"Loading CSV: {csv_path}")
        df_csv = pd.read_csv(csv_path)
    else:
        print(f"CSV not found at {csv_path}.")

    # Try to find latest unizulu Excel file (generated by the UI)
    excel_files = glob.glob('unizulu_*.xlsx') + glob.glob('*.xlsx')
    excel_files = [p for p in excel_files if os.path.basename(p).startswith('unizulu_')]
    df_xlsx = None
    if excel_files:
        # pick the most recently modified
        excel_files.sort(key=lambda p: os.path.getmtime(p), reverse=True)
        excel_path = excel_files[0]
        print(f"Loading Students sheet from Excel: {excel_path}")
        try:
            xls = pd.ExcelFile(excel_path)
            if 'Students' in xls.sheet_names:
                df_xlsx = pd.read_excel(xls, 'Students')
            else:
                # fallback to first sheet
                df_xlsx = pd.read_excel(xls, xls.sheet_names[0])
        except Exception as e:
            print('Failed to read excel file:', e)

    # If both present, merge on student_id (prefer values from CSV for target)
    if df_csv is not None and df_xlsx is not None:
        if 'student_id' in df_csv.columns and 'student_id' in df_xlsx.columns:
            merged = pd.merge(df_xlsx, df_csv, on='student_id', how='left', suffixes=('_xls', '_csv'))
            # If Performance in csv, use that, else look for in xls
            if 'Performance' in merged.columns:
                df = merged
            else:
                df = merged
        else:
            # Can't merge, just concat columns side-by-side
            df = pd.concat([df_xlsx, df_csv], axis=1)
    elif df_csv is not None:
        df = df_csv
    elif df_xlsx is not None:
        df = df_xlsx
    else:
        raise FileNotFoundError('No CSV or matching Excel file found in working directory.')

    return df


def preprocess(df, target_col='Performance'):
    # Basic checks
    if target_col not in df.columns:
        # Attempt to create a fallback binary target from assessment_avg or assignment_avg
        print(f"Warning: Target column '{target_col}' not found. Attempting to create a fallback target from 'assessment_avg' or 'assignment_avg'.")
        if 'assessment_avg' in df.columns:
            df[target_col] = df['assessment_avg'].astype(float).apply(lambda v: 'Pass' if v >= 50 else 'Fail')
            print("Created 'Performance' from 'assessment_avg' using threshold >=50 -> Pass")
        elif 'assignment_avg' in df.columns:
            df[target_col] = df['assignment_avg'].astype(float).apply(lambda v: 'Pass' if v >= 50 else 'Fail')
            print("Created 'Performance' from 'assignment_avg' using threshold >=50 -> Pass")
        else:
            raise ValueError(f"Target column '{target_col}' not found in data."
                             " Please provide a dataset with a 'Performance' column (e.g. Pass/Fail),"
                             " or include 'assessment_avg'/'assignment_avg' to derive one automatically.")

    # Work on a copy
    data = df.copy()

    # Drop obvious non-feature and identifier columns early to avoid leakage
    drop_cols = [c for c in ['first_name', 'last_name', 'email', 'password_hash', 'student_id'] if c in data.columns]
    if drop_cols:
        print(f"Dropping identifier/non-feature columns: {drop_cols}")
        data = data.drop(columns=drop_cols)

    # Ensure target exists; if not try to derive
    if target_col not in data.columns:
        # Attempt to create a fallback binary target from assessment_avg or assignment_avg
        print(f"Warning: Target column '{target_col}' not found. Attempting to create a fallback target from 'assessment_avg' or 'assignment_avg'.")
        if 'assessment_avg' in data.columns:
            data[target_col] = data['assessment_avg'].astype(float).apply(lambda v: 'Pass' if v >= 50 else 'Fail')
            print("Created 'Performance' from 'assessment_avg' using threshold >=50 -> Pass")
        elif 'assignment_avg' in data.columns:
            data[target_col] = data['assignment_avg'].astype(float).apply(lambda v: 'Pass' if v >= 50 else 'Fail')
            print("Created 'Performance' from 'assignment_avg' using threshold >=50 -> Pass")
        else:
            raise ValueError(f"Target column '{target_col}' not found in data. Please provide a dataset with a 'Performance' column or include 'assessment_avg'/'assignment_avg'.")

    X = data.drop(columns=[target_col])
    y = data[target_col]

    # map target to binary if categorical
    if y.dtype == 'object' or y.dtype.name == 'category':
        y = y.astype(str)
        y = y.map(lambda v: 1 if str(v).lower() in ['pass', 'passed', '1', 'true', 'yes'] else 0)

    return X, y


def build_pipeline(X):
    # Determine column types
    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()

    # Transformers
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    preprocessor = ColumnTransformer(transformers=[
        ('num', numeric_transformer, numeric_cols),
        ('cat', categorical_transformer, categorical_cols)
    ], remainder='drop')

    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('clf', RandomForestClassifier(n_estimators=200, random_state=42))
    ])

    return pipeline


def train_and_evaluate(X, y, model_path='student_risk_model.pkl'):
    # Drop any id-like columns if present (safety)
    X = X.copy()
    X = X.drop(columns=[c for c in ['student_id', 'password_hash'] if c in X.columns], errors='ignore')

    n_samples = len(y)
    # Choose CV folds safely
    try:
        min_class_count = np.min(np.bincount(y.astype(int)))
        cv_folds = min(5, max(2, min_class_count))
    except Exception:
        cv_folds = 2

    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)

    pipeline = build_pipeline(X)

    print('\nRunning cross-validated evaluation (out-of-fold)...')
    try:
        y_pred_cv = cross_val_predict(pipeline, X, y, cv=cv)
    except Exception as e:
        print('Cross-val predict failed:', e)
        y_pred_cv = None

    if y_pred_cv is not None:
        try:
            y_proba_cv = cross_val_predict(pipeline, X, y, cv=cv, method='predict_proba')[:, 1]
        except Exception:
            y_proba_cv = y_pred_cv

        acc = accuracy_score(y, y_pred_cv)
        prec = precision_score(y, y_pred_cv, zero_division=0)
        rec = recall_score(y, y_pred_cv, zero_division=0)
        f1 = f1_score(y, y_pred_cv, zero_division=0)
        cm = confusion_matrix(y, y_pred_cv)
        try:
            roc_auc = roc_auc_score(y, y_proba_cv)
        except Exception:
            roc_auc = float('nan')
        try:
            mse = mean_squared_error(y, y_proba_cv)
            rmse = np.sqrt(mse)
        except Exception:
            rmse = float('nan')

        print('\nCross-validated model evaluation (out-of-fold):')
        print(f'Accuracy: {acc:.4f}')
        print(f'Precision: {prec:.4f}')
        print(f'Recall: {rec:.4f}')
        print(f'F1-score: {f1:.4f}')
        print(f'ROC-AUC: {roc_auc:.4f}')
        print(f'RMSE (on predicted probability): {rmse:.4f}')
        print('\nConfusion Matrix:')
        print(cm)
        print('\nClassification Report:')
        print(classification_report(y, y_pred_cv, zero_division=0))

    # Hyperparameter tuning with RandomizedSearchCV
    param_dist = {
        'clf__n_estimators': [100, 200, 400],
        'clf__max_depth': [None, 5, 10, 20],
        'clf__min_samples_leaf': [1, 2, 4],
        # 'auto' is invalid in newer scikit-learn versions (raises InvalidParameterError).
        # Use 'sqrt', 'log2', a float fraction (e.g. 0.5), an int, or None.
        'clf__max_features': ['sqrt', 'log2', 0.5, None]
    }

    search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=10,
                                scoring='f1', n_jobs=1, cv=cv, random_state=42, verbose=1, refit=True)
    print('\nRunning hyperparameter search (RandomizedSearchCV) ...')
    try:
        search.fit(X, y)
    except Exception as e:
        print('Hyperparameter search failed:', e)
        # Fallback: fit base pipeline on full data
        pipeline.fit(X, y)
        best_model = pipeline
    else:
        best_model = search.best_estimator_
        print(f'Best params: {search.best_params_}')

    # Save evaluation artifacts
    try:
        report = classification_report(y, y_pred_cv, output_dict=True, zero_division=0)
    except Exception:
        report = None

    eval_out = {
        'n_samples': int(n_samples),
        'cv_folds': int(cv.get_n_splits()),
        'cv_metrics': {
            'accuracy': float(acc) if 'acc' in locals() else None,
            'precision': float(prec) if 'prec' in locals() else None,
            'recall': float(rec) if 'rec' in locals() else None,
            'f1': float(f1) if 'f1' in locals() else None,
            'roc_auc': float(roc_auc) if 'roc_auc' in locals() else None,
            'rmse': float(rmse) if 'rmse' in locals() else None,
        },
        'classification_report': report,
    }
    try:
        with open('evaluation_report.json', 'w', encoding='utf-8') as fo:
            json.dump(eval_out, fo, indent=2)
        # save confusion matrix
        import pandas as _pd
        _pd.DataFrame(cm).to_csv('confusion_matrix.csv', index=False, header=False)
        print('Saved evaluation_report.json and confusion_matrix.csv')
    except Exception as e:
        print('Failed to save evaluation artifacts:', e)

    # Save best model/pipeline
    joblib.dump(best_model, model_path)
    print(f'Model pipeline saved to {model_path}')

    return best_model


def explain_random_forest():
    expl = (
        "Why Random Forest is a good choice:\n"
        "- Handles mixed numeric/categorical features without extensive scaling.\n"
        "- Robust to noisy features and outliers because it averages many trees.\n"
        "- Captures non-linear relationships and interactions automatically.\n"
        "- Provides feature importance for interpretability.\n"
        "- Tends to generalize well with reasonable default hyperparameters.\n"
        "\nHowever, it's good practice to compare with other models and tune hyperparameters."
    )
    print('\n' + expl + '\n')


def main():
    parser = argparse.ArgumentParser(description='Train student performance model using CSV and Excel (if present).')
    parser.add_argument('--csv', default='student_records11.csv', help='Path to CSV file')
    parser.add_argument('--target', default='Performance', help='Name of the target column')
    parser.add_argument('--model-out', default='student_risk_model.pkl', help='Path to save trained model')
    args = parser.parse_args()

    df = load_data(args.csv)
    print('\nData preview:')
    print(df.head())

    X, y = preprocess(df, target_col=args.target)

    model = train_and_evaluate(X, y, model_path=args.model_out)
    explain_random_forest()


if __name__ == '__main__':
    main()